{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import pyodbc\n",
    "import os\n",
    "import itertools\n",
    "import json\n",
    "import re\n",
    "from json import JSONDecoder\n",
    "from sc_header import createDriver,aplanar_lista,extract_json_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(pos_aux,tipo_aux,url_aux,precio_aux,precio_dto_aux,pagina_aux):    \n",
    "    \n",
    "    lista_auxiliar = []\n",
    "    soup = BeautifulSoup(requests.get(url_aux).text,'html.parser')\n",
    "    try:\n",
    "        color = soup.find(class_='_colorName').text\n",
    "    except:\n",
    "        return [-1,1,-1,-1,-1,-1,-1,-1,-1,-1]\n",
    "    \n",
    "    id_producto = soup.find('html').get('id')\n",
    "    lista_auxiliar.append([pos_aux,\n",
    "                           id_producto, #ID PRODUCTO\n",
    "                           tipo_aux,\n",
    "                           color, #COLOR\n",
    "                           soup.find('title').text.split('|')[0].strip(), #DESC\n",
    "                           precio_aux,\n",
    "                           precio_dto_aux,\n",
    "                           soup.find(class_='_seoImg main-image').get('href'), #IMG\n",
    "                           url_aux,#URL\n",
    "                           pagina_aux,\n",
    "    ])\n",
    "    \n",
    "    return lista_auxiliar    \n",
    "\n",
    "#PAGINA_SCRAPER\n",
    "\n",
    "def scrape_batch(url_chunk):\n",
    "    chunk_resp = []\n",
    "    for url in url_chunk:\n",
    "        chunk_resp.append(scrape_url(url[0],url[1],url[4],url[3],url[2],url[5]))\n",
    "                                    \n",
    "    return chunk_resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://www.zara.com/mx/es/mujer-nuevo-l1180.html?v1=1445759'\n",
    "url_rebajas = 'https://www.zara.com/mx/es/mujer-l1000.html?v1=693100'\n",
    "fecha = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = createDriver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(url_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "\n",
    "elementos_ul = browser.find_elements_by_css_selector('._category-link-wrapper.menu-item.menu-item--level-3.menu-item--is-leaf')\n",
    "\n",
    "hover = ActionChains(browser).move_to_element(elementos_ul[0])\n",
    "hover.perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(url_base)\n",
    "categorias = ['COLLECTION','REBAJAS']\n",
    "elementos_ul = browser.find_elements_by_css_selector('._category-link-wrapper.menu-item.menu-item--level-3.menu-item--is-leaf')\n",
    "url_list = []\n",
    "for link in categorias:\n",
    "    \n",
    "    hover = ActionChains(browser).move_to_element(elementos_ul[0])\n",
    "    hover.perform()\n",
    "    time.sleep(2)\n",
    "    WebDriverWait(browser,50).until(EC.presence_of_element_located((By.LINK_TEXT,link))).click()\n",
    "\n",
    "    #elementos_ul = browser.find_elements_by_css_selector('._category-link-wrapper.menu-item.menu-item--level-3.menu-item--is-leaf')\n",
    "    tipos = []\n",
    "    ul = browser.find_element_by_css_selector('._subcategories.subcategory-menu.subcategory-menu--level-2.subcategory-menu--current')\n",
    "    lis = ul.find_elements_by_tag_name('li')\n",
    "\n",
    "    for indices, m in enumerate(lis):\n",
    "        try:\n",
    "            text_aux = browser.find_element_by_css_selector('._subcategories.subcategory-menu.subcategory-menu--level-2.subcategory-menu--current').find_elements_by_tag_name('li')[indices]\n",
    "        except:\n",
    "            continue\n",
    "        if text_aux.text != \"\":\n",
    "            if text_aux.text not in ['ÃšLTIMA SEMANA','ZAPATOS','BOLSOS','ACCESORIOS','NEWMUM','TARJETA REGALO']:\n",
    "                tipo = text_aux.text\n",
    "                tipos.append(tipo)\n",
    "\n",
    "                    #browser.execute_script('history.back();')\n",
    "    for element in tipos:\n",
    "\n",
    "        try:\n",
    "            if len(element.split()) > 1 :\n",
    "                hola\n",
    "\n",
    "\n",
    "            for _ in range(10):\n",
    "                try:\n",
    "                    WebDriverWait(browser,80).until(EC.element_to_be_clickable((By.LINK_TEXT,element))).click()\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(.2)\n",
    "        except:\n",
    "\n",
    "            for _ in range(10):\n",
    "                try:\n",
    "                    WebDriverWait(browser,80).until(EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT,element.split()[0]))).click()\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(.2)\n",
    "\n",
    "\n",
    "\n",
    "        url_list.append([element,browser.current_url])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.DataFrame(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = urls[(urls[0]!='A PARTIR DE -60%')&\n",
    "            (urls[0]!='ACCESORIOS')&\n",
    "            (urls[0]!='ZAPATOS')&\n",
    "            (urls[0]!='BOLSOS')\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls.rename(columns={0:'tipo',\n",
    "                    1:'url'},\n",
    "           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs_list = []\n",
    "for index,row in urls.iterrows():\n",
    "    try:\n",
    "        browser.get(row['url'])\n",
    "    except:\n",
    "        browser.quit()\n",
    "        time.sleep(1)\n",
    "        browser = createDriver2()\n",
    "        continue\n",
    "    \n",
    "    ELEMENTS_A = browser.find_elements_by_css_selector('a.item._item')\n",
    "                                                         \n",
    "    soup = BeautifulSoup(browser.page_source)\n",
    "    \n",
    "    for indices, element in enumerate(ELEMENTS_A):\n",
    "        \n",
    "        for i in soup.find_all(class_='price _product-price'):\n",
    "                try:\n",
    "                    precio = i.find(class_='main-price').get('data-price')\n",
    "                    precio_dto = precio\n",
    "                except:\n",
    "                    precio = i.find(class_='line-through').get('data-price')\n",
    "                    precio_dto = i.find(class_='sale').get('data-price')\n",
    "\n",
    "        hrefs_list.append([indices,row['tipo'],precio_dto,precio,element.get_attribute('href'),row['url']            \n",
    "        ])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "url_chunks = [hrefs_list[x:x+batch_size] for x in range(0, len(hrefs_list), batch_size)]\n",
    "items = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url_chunk in url_chunks:\n",
    "    items.append(scrape_batch(url_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = aplanar_lista(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0:'pos',\n",
    "                  1:'id_producto',\n",
    "                  2:'tipo',\n",
    "                  3:'color',\n",
    "                  4:'descripcion',\n",
    "                  5:'precio',\n",
    "                  6:'precio_dto',\n",
    "                  7:'img',\n",
    "                  8:'url',\n",
    "                  9:'pagina_scraper'},\n",
    "          inplace=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_sc3_producto,id_sc3_corrida,marca,tipo,tipo_es,color,color_es,sexo,descripcion,moneda,precio,precio_original,fecha_alta,url_imagen,url_producto,origen,tipo_juana,grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['marca'] ='ZARA'\n",
    "df['tipo_es'] = df['tipo']\n",
    "df['color_es'] = df['color']\n",
    "df['sexo'] = 'Mujer'\n",
    "df['moneda'] = 'PESO MXN'\n",
    "df['origen'] = 'ZARA MX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id_producto'] = df['id_producto'].apply(lambda x:x.split('-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['precio'] = (df['precio']\n",
    "                .str.extract(r\"([\\d,\\.]+)\", expand=False)\n",
    "                .str.replace(\".\", \"\")\n",
    "                .str.replace(\",\", \".\")\n",
    "                .astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['precio_dto'] = (df['precio_dto']\n",
    "                    .str.extract(r\"([\\d,\\.]+)\", expand=False)\n",
    "                    .str.replace(\".\", \"\")\n",
    "                    .str.replace(\",\", \".\")\n",
    "                    .astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(f'zara{fecha}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook zara.ipynb to script\n",
      "[NbConvertApp] Writing 7225 bytes to zara.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script zara.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev_env]",
   "language": "python",
   "name": "conda-env-dev_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
