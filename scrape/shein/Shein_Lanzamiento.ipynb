{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from time import strftime\n",
    "import datetime\n",
    "import time\n",
    "from pandas import ExcelWriter\n",
    "import re\n",
    "import pyodbc\n",
    "import asyncio\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import numpy as np\n",
    "import pdb\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from json import JSONDecoder\n",
    "from sc_header import aplanar, aplanar_lista,createDriver, extract_json_objects, scrape_url, scrape_batch, agregar_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createDriver():\n",
    "\n",
    "# user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'    \n",
    "\n",
    "# chrome_options = Options()  \n",
    "# chrome_options.add_argument(\"--headless\")  \n",
    "# chrome_options.add_argument(\"--no-sandbox\")\n",
    "# chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "# chrome_options.add_argument(\"--window-size=1825x1644\")\n",
    "# chromeOptions.addArguments(\"--disable-popup-blocking\")\n",
    "# chromeOptions.addArguments(\"--disable-notifications\")\n",
    "# chromeOptions.addArguments(\"--window-size=1920,1080\")\n",
    "\n",
    "# browser = webdriver.Chrome('/usr/bin/chromedriver', options = chrome_options)\n",
    "browser = createDriver()\n",
    "browser.delete_all_cookies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://www.shein.com/daily-new.html?cat_ids=2030,2032&ici=www_tab01navbar01&scici=navbar_2~~tab01navbar01~~1~~webLink~~~~0~~0'\n",
    "\n",
    "browser.get(url_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browser.save_screenshot('asd.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLICK EN MODAL\n",
    "try:\n",
    "    browser.find_element_by_css_selector('body > div.c-outermost-ctn > div.c-vue-coupon > div.coupon-mask.she-scroll-hide > div > i').click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browser.find_element_by_css_selector('.nav2-sec-ctn.j-nav2-sec-ctn.j-sa-nav2-sec-ctn').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha = browser.find_element_by_css_selector('.filter-title.level-title.leftnav-second-title').find_element_by_tag_name('a')\n",
    "fecha_alta = fecha.text\n",
    "fecha.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_element = browser.find_element_by_css_selector('.list-classify-filter.list-indent-one.j-fold-category-ctn').find_element_by_tag_name('li').find_element_by_tag_name('a')\n",
    "women = women_element.text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLICK EN WOMEN\n",
    "women_element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = browser.find_elements_by_css_selector('.list-classify-filter.list-indent-one')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_cat = []\n",
    "\n",
    "for cat in category_list.find_elements_by_tag_name('li'):\n",
    "    \n",
    "    html_cat.append([cat.find_element_by_tag_name('a').get_attribute('href'),\n",
    "                     cat.find_element_by_tag_name('a').get_attribute('data-cat-url-name')])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINK_CATEGORIAS = [i for i in html_cat if i[1] in ['Clothing','Lingerie & Loungewear','Beachwear','Activewear']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def agregar_links(url_aux,driver,lista,tipologia_aux,url_concat):\n",
    "    time.sleep(1)\n",
    "    driver.get(url_aux)\n",
    "#     pickle.dump(browser.get_cookies() , open(\"cookies.pkl\",\"wb\"))\n",
    "#     cookies = pickle.load(open(\"cookies.pkl\", \"rb\"))\n",
    "#     for cookie in cookies:\n",
    "#         browser.add_cookie(cookie)\n",
    "    \n",
    "    for elements in browser.find_elements_by_css_selector('.list-line-decorate.j-attr-filter'):\n",
    "        \n",
    "        if elements.find_element_by_tag_name('li').text == 'Color':\n",
    "        #if elements.text == 'Color':\n",
    "            print(tipologia_aux)\n",
    "\n",
    "            for color in elements.find_elements_by_class_name('j-auto-attrlink'):\n",
    "\n",
    "                lista.append([tipologia_aux,\n",
    "                              color.get_attribute('data-attrvalue'),\n",
    "                              color.get_attribute('href')])\n",
    "                \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clothing\n",
      "Lingerie & Loungewear\n",
      "Beachwear\n",
      "Activewear\n"
     ]
    }
   ],
   "source": [
    "Tlistas = []\n",
    "browser = createDriver()\n",
    "url_base = 'https://www.shein.com'\n",
    "for lsc in LINK_CATEGORIAS:\n",
    "    \n",
    "    agregar_links(lsc[0],\n",
    "                 browser,\n",
    "                 Tlistas,\n",
    "                 lsc[1],\n",
    "                 url_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browser.delete_all_cookies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs_list = []\n",
    "ex_col = []\n",
    "\n",
    "for lista in Tlistas:\n",
    "    \n",
    "#for lista in Tlistas[4:]:\n",
    "\n",
    "    try:\n",
    "        browser.delete_all_cookies()\n",
    "        browser.get(lista[2])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        soup = BeautifulSoup(browser.page_source,'html.parser')\n",
    "\n",
    "        indice_= 0\n",
    "        \n",
    "        if soup.select('div.j-switch-color-wrap > div.c-goodsitem__ratiowrap > a') == []: raise\n",
    "            \n",
    "        for element in soup.select('div.j-switch-color-wrap > div.c-goodsitem__ratiowrap > a'):\n",
    "        #for element in soup.find_all(class_='c-goodsitem__ratioimg j-item-msg j-item-msg-a j-expose__target-goods-img'):\n",
    "            \n",
    "            \n",
    "            href_aux = url_base + element.get('href')\n",
    "\n",
    "            hrefs_list.append([indice_,\n",
    "                               lista[0],\n",
    "                               lista[1],\n",
    "                               lista[2],\n",
    "                               href_aux\n",
    "                              ])\n",
    "            indice_+=1\n",
    "                \n",
    "            #except:\n",
    "            #    raise\n",
    "            #    ex_col.append([lista[0],lista[2],lista[1]])\n",
    "            #    pass            \n",
    "        try:\n",
    "            browser.find_element_by_class_name('page-next').find_element_by_tag_name('a').click()\n",
    "        except:\n",
    "            break\n",
    "#browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup.find_all(class_='c-goodsitem__ratioimg j-item-msg j-item-msg-a j-expose__target-goods-img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hrefs_list,columns=['pos','tipo','color','url_scraper','href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Clothing', 'Lingerie & Loungewear', 'Beachwear', 'Activewear'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tipo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_length(serie):\n",
    "    \n",
    "    #if menor a 8 es porque hay un link donde el max es un numero que no es el id_producto\n",
    "    ##caso especial : 'https://www.shein.com/skdress07191118781-p-929597-cat-2005.html?scici=homepage_164~~0_Banner_1_0_hotZone_w7bymbmsz~~3_2~~real_1991~~ccc_shein_pc_kids-homepage_default~~0~~50001'\n",
    "    return str(max([X for X in map(int,re.findall(r\"([\\d]+)\",serie)) if len(str(X))<8]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['auxi'] = df['href'].apply(check_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(562, 562)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.drop_duplicates()),len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#active = [i for i in Tlistas if i[0] == 'Activewear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df['tipo'].unique().tolist()) != len(set([item[0] for item in Tlistas])):\n",
    "    print('REVISAR LOS TIPOS SCRAPEADOS')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['tipo'].unique().tolist()),len(set([item[0] for item in Tlistas]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_url(errores,items,url_aux,pos_aux,url_scraper,aux_tipologia,aux_color):\n",
    "    \n",
    "#     #lista_auxiliar = []\n",
    "#     url = url_aux\n",
    "#     for _ in range(5):\n",
    "#         try:\n",
    "#             txt = re.findall(r'productIntroData\\s*:\\s*({.*})', requests.get(url).text)\n",
    "#             txt = txt[0]\n",
    "#             break\n",
    "#         except:\n",
    "#             pass\n",
    "#     try:\n",
    "#         data = json.loads(txt)\n",
    "#     except:\n",
    "#         errores.append([url_aux,pos_aux,url_scraper,aux_tipologia,aux_color])\n",
    "#         return \n",
    "\n",
    "#     #ID\n",
    "#     codigo = data['detail']['goods_sn']\n",
    "#     #DESCRIPCION\n",
    "#     descripcion = data['detail']['goods_url_name']\n",
    "#     #PRECIO \n",
    "#     precio = data['detail']['retailPrice']['amount']\n",
    "#     #PRECIO CON DTO\n",
    "#     precio_dto = data['detail']['salePrice']['amount']\n",
    "#     #JPG\n",
    "#     jpg = data['detail']['original_img']\n",
    "\n",
    "#     for item in data['attrSizeList']:\n",
    "        \n",
    "#         items.append([pos_aux,\n",
    "#                       aux_tipologia,\n",
    "#                       aux_color,\n",
    "#                       codigo,\n",
    "#                       descripcion,\n",
    "#                       item['attr_value_en'],\n",
    "#                       item['stock'],\n",
    "#                       precio,\n",
    "#                       precio_dto,\n",
    "#                       jpg,\n",
    "#                       url_aux,\n",
    "#                       url_scraper])\n",
    "#     #return lista_auxiliar\n",
    "\n",
    "# def scrape_batch(errores,items,url_chunk):\n",
    "#     #chunk_resp = []\n",
    "#     for indices,fila in url_chunk.iterrows():\n",
    "#         scrape_url(errores,items,fila['href'],fila['pos'],fila['url_scraper'],fila['tipo'],fila['color'])\n",
    "                     \n",
    "#     #return chunk_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ = datetime.datetime.now()\n",
    "items = []\n",
    "errores = []\n",
    "\n",
    "batch_size = 5\n",
    "url_chunks = [df[x:x+batch_size] for x in range(0, len(df), batch_size)]\n",
    "\n",
    "var = 0\n",
    "for ix, url_chunk in enumerate(url_chunks):\n",
    "    scrape_batch(errores,items,url_chunk)\n",
    "    \n",
    "    if int(ix/50) == ix/50:\n",
    "        \n",
    "        try:\n",
    "            df = pd.DataFrame(items)\n",
    "            df.to_excel('lanzamiento.xlsx')\n",
    "            \n",
    "            if len(errores) >0:\n",
    "                \n",
    "                pd.DataFrame(errores).to_excel('lanzamiento_error.xlsx')\n",
    "                \n",
    "            file = open(\"lanzamiento.txt\", \"w\")\n",
    "            file.write( str(url_chunk) + os.linesep)\n",
    "            file.close()\n",
    "        except:\n",
    "            print(\"Erro al crear .xlsx\")    \n",
    "    \n",
    "end_ = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_ = datetime.datetime.now()\n",
    "# items = []\n",
    "\n",
    "# batch_size = 5\n",
    "# url_chunks = [df[x:x+batch_size] for x in range(0, len(df), batch_size)]\n",
    "\n",
    "# var = 0\n",
    "# for url_chunk in url_chunks:\n",
    "#     items.append(scrape_batch(url_chunk))\n",
    "#     var += 1\n",
    "    \n",
    "#     if var == 30:\n",
    "#         var = 0\n",
    "#         try:\n",
    "#             df = pd.DataFrame(items)\n",
    "#             df.to_excel('lanzamiento.xlsx')\n",
    "            \n",
    "                                                                                            \n",
    "#             file = open(\"lanzamiento.txt\", \"w\")\n",
    "#             file.write( str(url_chunk) + os.linesep)\n",
    "#             file.close()\n",
    "#         except:\n",
    "#             print(\"Erro al crear .xlsx\")\n",
    "        \n",
    "    \n",
    "# end_ = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 0:55:39.61\n"
     ]
    }
   ],
   "source": [
    "print('Tiempo de ejecución: {}'.format(end_ - start_)[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_list = aplanar(items)\n",
    "\n",
    "# new_list =[ i for i in new_list if type(i) != int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0:'pos',\n",
    "                  1:'tipo',\n",
    "                  2:'color',\n",
    "                  3:'sku',\n",
    "                  4:'descripcion',\n",
    "                  5:'talle',\n",
    "                  6:'stock',\n",
    "                  7:'precio',\n",
    "                  8:'precio_dto',\n",
    "                  9:'img',\n",
    "                  10:'url',\n",
    "                  11:'pagina_scraper'\n",
    "                  },inplace=True)\n",
    "df['fecha_alta'] = fecha_alta\n",
    "df[\"marca\"] = \"SHEIN\"\n",
    "df[\"moneda\"] = \"DOLAR US$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"precio_dto\"] = (df[\"precio_dto\"]\n",
    "                .str.extract(r\"([\\d,\\.]+)\", expand=False)\n",
    "                .str.replace(\",\", \".\")\n",
    "                .astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"precio\"] = (df[\"precio\"]\n",
    "                .str.extract(r\"([\\d,\\.]+)\", expand=False)\n",
    "                .str.replace(\",\", \".\")\n",
    "                .astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sexo'] ='Mujer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha = datetime.date.today()\n",
    "df.to_excel('../Salida/lanzamiento'+str(fecha)+'.xlsx')\n",
    "# writer = ExcelWriter('../Salida/lanzamiento'+str(fecha)+'.xlsx')\n",
    "# df.to_excel(writer,'Hoja1')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT\n",
    "server = 'tcp:192.168.1.6'\n",
    "database =\"planeamiento\"\n",
    "username = 'sa'\n",
    "password = 'sa'\n",
    "cnxn = pyodbc.connect('DRIVER={/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.2.so.0.1};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = cnxn.cursor()\n",
    "for index,row in df.iterrows():                                               \n",
    "    try:\n",
    "        cursor.execute(\"INSERT INTO sc_lanzamiento([sku],[pos],[talle],[color],[tipo],[marca],[sexo],[descripcion],[stock],[precio],[precio_dto],[fecha_alta],[moneda],[img],[url],[pagina_scraper]) values (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\", \n",
    "                       row['sku'], \n",
    "                       row['pos'], \n",
    "                       row['talle'],\n",
    "                       row['color'],\n",
    "                       row['tipo'],\n",
    "                       row['marca'],\n",
    "                       row['sexo'],\n",
    "                       row['descripcion'],\n",
    "                       row['stock'],\n",
    "                       row['precio'],\n",
    "                       row['precio_dto'], \n",
    "                       row['fecha_alta'], \n",
    "                       row['moneda'],\n",
    "                       row['img'], \n",
    "                       row['url'],\n",
    "                       row['pagina_scraper']\n",
    "                      ) \n",
    "        cnxn.commit()\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(e)\n",
    "        print(\"*\"*100)\n",
    "        print(row)\n",
    "        raise\n",
    "cursor.close()\n",
    "cnxn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-9c9a2cba73bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "pathlib.Path().absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev_env]",
   "language": "python",
   "name": "conda-env-dev_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
