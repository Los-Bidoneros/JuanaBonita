{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from time import strftime\n",
    "import datetime\n",
    "import time\n",
    "from pandas import ExcelWriter\n",
    "import re\n",
    "import pyodbc\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import numpy as np\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "import selenium\n",
    "import itertools\n",
    "import json\n",
    "from sc_header import createDriver, agregar_links, scrape_url, scrape_batch, aplanar_lista,check_length, aplanar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ = datetime.datetime.now()\n",
    "fecha = datetime.date.today()\n",
    "hoy = fecha.strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = createDriver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.delete_all_cookies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get('https://www.shein.com/women-dresses-c-1727.html?icn=women-dresses&ici=www_tab01navbar05')\n",
    "try:\n",
    "    browser.execute_script('document.querySelector(\"body > div.welcome-privacy.j-welcome-privacy > div > div.c-modal-wrap.welocme-modal > div.c-modal > div > div > div.modal-body > div > div > button\").click()')\n",
    "except:\n",
    "    pass\n",
    "page = BeautifulSoup(browser.page_source,'html.parser')\n",
    "url_base = 'https://www.shein.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browser.delete_all_cookies()\n",
    "links_sin_color =[['https://www.shein.com/women-dresses-c-1727.html?icn=women-dresses&ici=www_tab01navbar05',\n",
    "                 'VESTIDO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tlistas = []\n",
    "for lsc in links_sin_color:\n",
    "    \n",
    "    agregar_links(lsc[0],\n",
    "                 browser,\n",
    "                 Tlistas,\n",
    "                 lsc[1],\n",
    "                 url_base)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browser.save_screenshot(\"asd.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs_list = []\n",
    "ex_col = []\n",
    "for lista in Tlistas:\n",
    "    try:\n",
    "        browser.get(lista[2])\n",
    "    except:\n",
    "        browser.quit()\n",
    "        time.sleep(1)\n",
    "        browser = createDriver()\n",
    "        browser.get(lista[2])\n",
    "        \n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        soup = BeautifulSoup(browser.page_source,'html.parser')\n",
    "        indice_=0\n",
    "        #for element in soup.find_all(class_='c-goodsitem__ratiowrap'):\n",
    "        for element in soup.select('div.j-switch-color-wrap > div.c-goodsitem__ratiowrap > a'):\n",
    "            href_aux = url_base +'/'+ element['href']\n",
    "\n",
    "            hrefs_list.append([indice_,\n",
    "                               lista[0],\n",
    "                               lista[1],\n",
    "                               lista[2],\n",
    "                               href_aux\n",
    "                              ])\n",
    "            indice_+=1\n",
    "                \n",
    "                        \n",
    "        try:\n",
    "            browser.find_element_by_class_name('page-next').find_element_by_tag_name('a').click()\n",
    "        except:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hrefs_list,columns=['pos','tipo','color','url_scraper','href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['auxi'] = df['href'].apply(check_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8979, 8979)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df),len(df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df['tipo'].unique().tolist()) != len(set([item[0] for item in Tlistas])):\n",
    "    print('REVISAR LOS TIPOS SCRAPEADOS')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ = datetime.datetime.now()\n",
    "items = []\n",
    "errores = []\n",
    "\n",
    "batch_size = 5\n",
    "url_chunks = [df[x:x+batch_size] for x in range(0, len(df), batch_size)]\n",
    "\n",
    "var = 0\n",
    "for ix, url_chunk in enumerate(url_chunks):\n",
    "    scrape_batch(errores,items,url_chunk)\n",
    "    \n",
    "    if int(ix/50) == ix/50:\n",
    "        \n",
    "        try:\n",
    "            df = pd.DataFrame(items)\n",
    "            df.to_excel('dress.xlsx')\n",
    "            \n",
    "            if len(errores) >0:\n",
    "                \n",
    "                pd.DataFrame(errores).to_excel('dress_error.xlsx')\n",
    "                \n",
    "            file = open(\"dress.txt\", \"w\")\n",
    "            file.write( str(url_chunk) + os.linesep)\n",
    "            file.close()\n",
    "        except:\n",
    "            print(\"Erro al crear .xlsx\")    \n",
    "    \n",
    "end_ = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_ = datetime.datetime.now()\n",
    "# items = []\n",
    "\n",
    "# batch_size = 5\n",
    "# url_chunks = [df[x:x+batch_size] for x in range(0, len(df), batch_size)]\n",
    "\n",
    "# var = 0\n",
    "# for url_chunk in url_chunks:\n",
    "#     items.append(scrape_batch(url_chunk))\n",
    "#     var += 1\n",
    "    \n",
    "#     if var == 50:\n",
    "#         var = 0\n",
    "#         try:\n",
    "#             df = pd.DataFrame(items)\n",
    "#             df.to_excel('dress.xlsx')\n",
    "                                                        \n",
    "#             file = open(\"dress.txt\", \"w\")\n",
    "#             file.write( str(url_chunk) + os.linesep)\n",
    "#             file.close()\n",
    "#         except:\n",
    "#             print(\"Erro al crear .xlsx\")\n",
    "    \n",
    "# end_ = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 11:44:37.18\n"
     ]
    }
   ],
   "source": [
    "print('Tiempo de ejecución: {}'.format(end_ - start_)[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = aplanar_lista(items)\n",
    "new_list = [i for i in new_list if type(i) != int]\n",
    "dfShein = pd.DataFrame(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfShein = dfShein.rename(columns={0: 'pos'})\n",
    "dfShein = dfShein.rename(columns={1: 'Tipo'})\n",
    "dfShein = dfShein.rename(columns={2: 'Color'})\n",
    "dfShein = dfShein.rename(columns={3: 'id Producto'})\n",
    "dfShein = dfShein.rename(columns={4: 'Descripcion'})\n",
    "dfShein = dfShein.rename(columns={5: 'Talle'})\n",
    "dfShein = dfShein.rename(columns={6: 'Stock'})\n",
    "dfShein = dfShein.rename(columns={7: 'Precio'})\n",
    "dfShein = dfShein.rename(columns={8: 'Precio_dto'})\n",
    "dfShein = dfShein.rename(columns={9: 'Url Imagen'})\n",
    "dfShein = dfShein.rename(columns={10: 'Url Producto'})\n",
    "dfShein = dfShein.rename(columns={11: 'pagina_scraper'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfShein[\"Fecha\"] = hoy\n",
    "dfShein[\"Marca\"] = \"SHEIN\"\n",
    "dfShein[\"Moneda\"] = \"DOLAR US$\"\n",
    "dfShein['Sexo'] = 'Mujer'\n",
    "dfShein['Descripcion aux'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paginas = len(dfShein['pagina_scraper'].unique())\n",
    "file = open(\"dress.txt\", \"a\")\n",
    "file.write(  os.linesep +f'CANTIDAD_ITEMS - {len(dfShein)},'+ f' DURACION - {format(end_ - start_)[:-4]},'+\n",
    "           f' CANTIDAD_HOJAS - {paginas},'+ f' FECHA_ALTA - {hoy}' + os.linesep   \n",
    "          )\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dfShein['Tipo'].unique().tolist()) != len(set([item[0] for item in Tlistas])):\n",
    "    print('REVISAR LOS TIPOS SCRAPEADOS')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfShein.to_excel(f'../Salida/dfShein_dress{fecha}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36186, 36186, 36186)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfShein),len(dfShein.dropna()),len(dfShein.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore = pd.read_excel('dress.xlsx')\n",
    "# lista_ = []\n",
    "# for col in restore.columns:\n",
    "#     for i in restore[col]:\n",
    "#         lista_ += [[elementos.strip().replace('\"', '').replace(\"'\", '') for elementos in i.strip('[]').split('], [')[0].split(',')]]\n",
    "        \n",
    "# for index,row in df.iterrows():\n",
    "#     if row['href'] == lista_[-1][-2]:\n",
    "#         print(index+1)\n",
    "#         break\n",
    "# #df = df.loc[index+1:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev_env]",
   "language": "python",
   "name": "conda-env-dev_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
